{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc65e9f",
   "metadata": {},
   "source": [
    "# Select Kernel\n",
    "\n",
    "Remember to select the appropriate Kernel and virtual environment to run on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c1da9",
   "metadata": {},
   "source": [
    "# Install common packages in Terminal prior to running\n",
    "\n",
    "pip install pandas\n",
    "pip install numpy\n",
    "pip install matplotlib\n",
    "pip install seaborn\n",
    "pip install scikit-learn\n",
    "pip install scipy\n",
    "\n",
    "To install all of the above at one time: \n",
    "pip install pandas numpy matplotlib seaborn scikit-learn scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e67af",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.13.1)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/hanko/Documents/MSBA_Projects/quantic_msba_SIMP_anly_mthd_frmwk/Simplified_MSBA_Analytics_Methods_Frameworks_Project/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('2025.09.29_2023_Sales_Transactions_Only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26387a37",
   "metadata": {},
   "source": [
    "# Data Overview and Initial Processing\n",
    "\n",
    "## Dataset Context\n",
    "- Source: Sales transactions data for 2023 from Crafted Cones\n",
    "- Timeframe: Full year 2023\n",
    "- Scope: Individual transaction records including monetary values, quantities, and customer information\n",
    "\n",
    "## Initial Data Loading Process\n",
    "- Raw data loaded from CSV file without modifications\n",
    "- No initial filtering or preprocessing applied\n",
    "- Subsequent cells will handle data cleaning and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c300a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: clean numeric/currency columns\n",
    "# Defines a reusable function to clean currency-like strings and coerce numeric columns.\n",
    "# Call this early after loading the DataFrame so downstream cells receive numeric columns.\n",
    "\n",
    "def clean_numeric_columns(df, currency_cols=None, numeric_cols=None, keep_raw=True, overwrite=True):\n",
    "    import pandas as pd\n",
    "    if currency_cols is None:\n",
    "        currency_cols = []\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = []\n",
    "\n",
    "    def _clean_currency_series(s):\n",
    "        s2 = s.astype(str).str.strip()\n",
    "        s2 = s2.replace('nan', '', regex=False)\n",
    "        # detect parentheses for negatives\n",
    "        neg_mask = s2.str.match(r'^\\(.*\\)$')\n",
    "        # remove parentheses\n",
    "        s2 = s2.str.replace(r'[\\(\\)]', '', regex=True)\n",
    "        # remove dollar signs, commas and whitespace\n",
    "        s2 = s2.str.replace(r'[\\$,\\s]', '', regex=True)\n",
    "        # prefix negatives\n",
    "        if neg_mask.any():\n",
    "            s2.loc[neg_mask] = '-' + s2.loc[neg_mask]\n",
    "        return pd.to_numeric(s2, errors='coerce')\n",
    "\n",
    "    for col in currency_cols:\n",
    "        if col in df.columns:\n",
    "            if keep_raw:\n",
    "                raw_col = f\"{col}_raw\"\n",
    "                # only create raw copy if not exists\n",
    "                if raw_col not in df.columns:\n",
    "                    df[raw_col] = df[col]\n",
    "            cleaned = _clean_currency_series(df[col])\n",
    "            if overwrite:\n",
    "                df[col] = cleaned\n",
    "            else:\n",
    "                df[f\"{col}_clean\"] = cleaned\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            coerced = pd.to_numeric(df[col], errors='coerce')\n",
    "            if overwrite:\n",
    "                df[col] = coerced\n",
    "            else:\n",
    "                df[f\"{col}_clean\"] = coerced\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example call: clean commonly problematic columns\n",
    "# This will create `Total_Amount_raw` and `Unit_Price_raw` (if they don't exist) and\n",
    "# create `Total_Amount_clean` and `Unit_Price_clean` columns (originals preserved).\n",
    "clean_numeric_columns(df,\n",
    "                      currency_cols=['Total_Amount','Unit_Price'],\n",
    "                      numeric_cols=['Quantity','Number_of_Scoops','Year','Month'],\n",
    "                      keep_raw=True,\n",
    "                      overwrite=False)\n",
    "\n",
    "print('Completed numeric cleaning: created *_clean columns; raw copies kept if not present.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd27e02",
   "metadata": {},
   "source": [
    "# Cleaning README: numeric cleaning contract\n",
    "\n",
    "\n",
    "This notebook applies a small, deterministic cleaning step to common numeric/currency columns. Contract summary:\n",
    "\n",
    "\n",
    "- Function: `clean_numeric_columns(df, currency_cols, numeric_cols, keep_raw=True, overwrite=False)`\n",
    "- Behavior:\n",
    "  - For each column in `currency_cols` (example: `['Total_Amount','Unit_Price']`):\n",
    "    - Create `{col}_raw` if `keep_raw=True` and `{col}_raw` does not already exist.\n",
    "    - Produce a cleaned numeric column named `{col}_clean` (unless `overwrite=True` is used).\n",
    "    - Cleaning handles: trimming whitespace, removing `$` and `,`, converting `(123.45)` to `-123.45`, and coercing invalid values to `NaN`.\n",
    "  - For each column in `numeric_cols` (example: `['Quantity','Number_of_Scoops','Year','Month']`):\n",
    "    - Coerce values to numeric and write to `{col}_clean` (or overwrite original if `overwrite=True`).\n",
    "\n",
    "- Post-condition: Analysis in this notebook should use `*_clean` columns (e.g., `Total_Amount_clean`, `Unit_Price_clean`, `Quantity_clean`, `Year_clean`, `Month_clean`).\n",
    "- If `*_clean` is absent, some cells may attempt to create it from `{col}_raw` or, as a last resort, from the original `{col}` with a clear warning — but the preferred source is always `{col}_clean`.\n",
    "\n",
    "Files produced by the notebook (examples): `total_amount_boxplot.png`, `total_amount_hist.png`.\n",
    "\n",
    "If you want the cleaned dataset saved to disk, call `df.to_csv('cleaned_sales.csv', index=False)` after verifying the `*_clean` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: show before/after samples for cleaned columns\n",
    "print('Column list (first 50):', list(df.columns)[:50])\n",
    "\n",
    "# Show Total_Amount raw vs clean\n",
    "if 'Total_Amount_raw' in df.columns:\n",
    "    print('\\nTotal_Amount_raw (first 5):')\n",
    "    print(df['Total_Amount_raw'].head().to_string())\n",
    "else:\n",
    "    print('\\nNo Total_Amount_raw column present')\n",
    "\n",
    "if 'Total_Amount_clean' in df.columns:\n",
    "    print('\\nTotal_Amount_clean (first 5):')\n",
    "    print(df['Total_Amount_clean'].head().to_string())\n",
    "    print(f\"Total_Amount_clean - non-null count: {df['Total_Amount_clean'].count()} / {len(df)}\")\n",
    "else:\n",
    "    print('\\nNo Total_Amount_clean column present')\n",
    "\n",
    "# Show Unit_Price raw vs clean\n",
    "if 'Unit_Price_raw' in df.columns:\n",
    "    print('\\nUnit_Price_raw (first 5):')\n",
    "    print(df['Unit_Price_raw'].head().to_string())\n",
    "else:\n",
    "    print('\\nNo Unit_Price_raw column present')\n",
    "\n",
    "if 'Unit_Price_clean' in df.columns:\n",
    "    print('\\nUnit_Price_clean (first 5):')\n",
    "    print(df['Unit_Price_clean'].head().to_string())\n",
    "    print(f\"Unit_Price_clean - non-null count: {df['Unit_Price_clean'].count()} / {len(df)}\")\n",
    "else:\n",
    "    print('\\nNo Unit_Price_clean column present')\n",
    "\n",
    "# Quick numeric summary of cleaned columns\n",
    "import numpy as np\n",
    "for c in ['Total_Amount_clean','Unit_Price_clean','Quantity_clean','Number_of_Scoops_clean']:\n",
    "    if c in df.columns:\n",
    "        print(f\"\\nSummary for {c}:\")\n",
    "        print(df[c].describe())\n",
    "    else:\n",
    "        print(f\"\\n{c} not present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reload check for the cleaned dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "clean_path = 'cleaned_sales.csv'\n",
    "print('Checking cleaned file:', clean_path)\n",
    "if not os.path.exists(clean_path):\n",
    "    print(f\"File not found: {clean_path}. Run the cell that saves the cleaned CSV first.\")\n",
    "else:\n",
    "    size = os.path.getsize(clean_path)\n",
    "    # compute sha256 to detect accidental changes\n",
    "    h = hashlib.sha256()\n",
    "    with open(clean_path, 'rb') as fh:\n",
    "        for chunk in iter(lambda: fh.read(8192), b''):\n",
    "            h.update(chunk)\n",
    "    sha256 = h.hexdigest()\n",
    "    print(f\"Exists: True  Size(bytes): {size}  SHA256: {sha256}\")\n",
    "\n",
    "    # Load a small sample to validate dtypes quickly\n",
    "    sample = pd.read_csv(clean_path, nrows=1000)\n",
    "    print('\\nSample load OK — shape (sample):', sample.shape)\n",
    "    print('\\nDtypes (sample):')\n",
    "    print(sample.dtypes)\n",
    "\n",
    "    # Lightweight checks on important cleaned columns\n",
    "    cols = [c for c in ['Total_Amount_clean','Unit_Price_clean','Quantity_clean','Number_of_Scoops_clean','Year_clean','Month_clean'] if c in sample.columns]\n",
    "    if cols:\n",
    "        print('\\nQuick summary for cleaned columns (sample):')\n",
    "        print(sample[cols].agg(['count','mean','std']).transpose())\n",
    "    else:\n",
    "        print('\\nNo expected *_clean columns found in sample — check the saved file and the cleaning steps.')\n",
    "\n",
    "    print('\\nYou can now re-load the full cleaned dataset with: df = pd.read_csv(\"cleaned_sales.csv\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm data load and show cleaned columns (if present)\n",
    "to_show = []\n",
    "for c in ['Total_Amount_raw','Total_Amount_clean','Unit_Price_raw','Unit_Price_clean','Quantity_clean','Number_of_Scoops_clean']:\n",
    "    if c in df.columns:\n",
    "        to_show.append(c)\n",
    "\n",
    "if to_show:\n",
    "    print('Showing head() for cleaned/raw columns:')\n",
    "    display_cols = df[to_show].head()\n",
    "    print(display_cols)\n",
    "else:\n",
    "    print('No cleaned/raw sample columns present; showing regular head()')\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm dataset volume \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)DATA UNDERSTANDING \n",
    "#Check Data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) DATA CLEANING \n",
    "#Get missing data per col \n",
    "missing_counts_per_column = df.isnull().sum() \n",
    "\n",
    "print(missing_counts_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4) OUTLIER DETECTION \n",
    "# Prefer working on `Total_Amount_clean`. If missing, attempt to create from\n",
    "# `Total_Amount_raw`. Only as a last-resort fallback will the original\n",
    "# `Total_Amount` be used (with a warning).\n",
    "\n",
    "def _ensure_total_amount_clean(df):\n",
    "    # If clean exists, nothing to do\n",
    "    if 'Total_Amount_clean' in df.columns:\n",
    "        return\n",
    "\n",
    "    # Try to create from raw copy if it exists\n",
    "    if 'Total_Amount_raw' in df.columns:\n",
    "        temp = df['Total_Amount_raw'].astype(str).str.strip()\n",
    "        temp = temp.replace('nan', '', regex=False)\n",
    "        neg_mask = temp.str.match(r'^\\(.*\\)$')\n",
    "        temp = temp.str.replace(r'[\\(\\)]', '', regex=True)\n",
    "        temp = temp.str.replace(r'[\\$,\\s]', '', regex=True)\n",
    "        if neg_mask.any():\n",
    "            temp.loc[neg_mask] = '-' + temp.loc[neg_mask]\n",
    "        df['Total_Amount_clean'] = pd.to_numeric(temp, errors='coerce')\n",
    "        print('Created Total_Amount_clean from Total_Amount_raw')\n",
    "        return\n",
    "\n",
    "    # Last-resort: if original column exists, create raw and clean but warn\n",
    "    if 'Total_Amount' in df.columns:\n",
    "        print('Warning: creating Total_Amount_clean from original Total_Amount (no raw copy present).')\n",
    "        temp = df['Total_Amount'].astype(str).str.strip()\n",
    "        temp = temp.replace('nan', '', regex=False)\n",
    "        neg_mask = temp.str.match(r'^\\(.*\\)$')\n",
    "        temp = temp.str.replace(r'[\\(\\)]', '', regex=True)\n",
    "        temp = temp.str.replace(r'[\\$,\\s]', '', regex=True)\n",
    "        if neg_mask.any():\n",
    "            temp.loc[neg_mask] = '-' + temp.loc[neg_mask]\n",
    "        # create raw copy then create clean\n",
    "        df['Total_Amount_raw'] = df['Total_Amount']\n",
    "        df['Total_Amount_clean'] = pd.to_numeric(temp, errors='coerce')\n",
    "        return\n",
    "\n",
    "    # If we reach here, there's no source to create Total_Amount_clean\n",
    "    raise RuntimeError('No Total_Amount column (raw or original) found to create Total_Amount_clean')\n",
    "\n",
    "\n",
    "_ensure_total_amount_clean(df)\n",
    "\n",
    "# Diagnostics: dtype and count of coerced (NaN) values\n",
    "print(f\"dtype of Total_Amount_clean: {df['Total_Amount_clean'].dtype}\")\n",
    "n_coerced = df['Total_Amount_clean'].isna().sum()\n",
    "print(f\"Number of rows where Total_Amount_clean could not be converted and were set to NaN: {n_coerced}\")\n",
    "if n_coerced > 0:\n",
    "    print(\"Sample rows with non-numeric Total_Amount after coercion:\")\n",
    "    print(df[df['Total_Amount_clean'].isna()].head())\n",
    "\n",
    "# Work with cleaned numeric values only\n",
    "column_to_analyze = df['Total_Amount_clean'].dropna()\n",
    "\n",
    "if column_to_analyze.empty:\n",
    "    print(\"No numeric values available in 'Total_Amount_clean' after conversion. Cannot compute IQR.\")\n",
    "else:\n",
    "    # Calculate Q1\n",
    "    Q1 = column_to_analyze.quantile(0.25)\n",
    "\n",
    "    # Calculate Q3\n",
    "    Q3 = column_to_analyze.quantile(0.75)\n",
    "\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the outlier boundaries (using the standard 1.5 * IQR rule)\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    print(\"--- IQR Results for Total_Amount_clean ---\")\n",
    "    print(f\"First Quartile (Q1): {Q1}\")\n",
    "    print(f\"Third Quartile (Q3): {Q3}\")\n",
    "    print(f\"Interquartile Range (IQR): {IQR}\")\n",
    "    print(f\"Lower Bound (Outliers below): {lower_bound}\")\n",
    "    print(f\"Upper Bound (Outliers above): {upper_bound}\")\n",
    "\n",
    "    # Find and print the outliers using the cleaned column\n",
    "    outliers = df[(df['Total_Amount_clean'] < lower_bound) | (df['Total_Amount_clean'] > upper_bound)]\n",
    "    print(f\"\\nNumber of Outliers Found: {len(outliers)}\")\n",
    "    # Use .head() to avoid printing all rows if you have many outliers\n",
    "    print(f\"First 5 Outlier Transactions:\\n{outliers.head()}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Alternative outlier detection methods and visualization (operate on Total_Amount_clean)\n",
    "# Create a clean column for alternative analyses if not already present (ensured above)\n",
    "\n",
    "# 1) Z-score method (use population std, threshold configurable)\n",
    "mean_val = df['Total_Amount_clean'].mean()\n",
    "std_val = df['Total_Amount_clean'].std(ddof=0)\n",
    "if pd.isna(std_val) or std_val == 0:\n",
    "    z_scores = pd.Series([0.0] * len(df), dtype=float)\n",
    "else:\n",
    "    z_scores = ((df['Total_Amount_clean'] - mean_val) / std_val).astype(float)\n",
    "z_threshold = float(3.0)\n",
    "outliers_z = df[z_scores.abs() > z_threshold]\n",
    "print(f\"\\nZ-score method (|z| > {z_threshold}): {len(outliers_z)} outliers\")\n",
    "\n",
    "# 2) Trimmed / scaled IQR method (allow multiplier > 1.5)\n",
    "multiplier = 3.0  # change to 1.5 for standard rule, raise to find more extreme outliers\n",
    "Q1_t = df['Total_Amount_clean'].quantile(0.25)\n",
    "Q3_t = df['Total_Amount_clean'].quantile(0.75)\n",
    "IQR_t = Q3_t - Q1_t\n",
    "lower_t = Q1_t - multiplier * IQR_t\n",
    "upper_t = Q3_t + multiplier * IQR_t\n",
    "outliers_trimmed = df[(df['Total_Amount_clean'] < lower_t) | (df['Total_Amount_clean'] > upper_t)]\n",
    "print(f\"Trimmed IQR method (multiplier={multiplier}): {len(outliers_trimmed)} outliers (bounds {lower_t} to {upper_t})\")\n",
    "\n",
    "# 3) Visualizations: boxplot and histogram (saved to PNG files)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "# Boxplot\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x=df['Total_Amount_clean'].dropna())\n",
    "plt.title('Boxplot of Total_Amount (clean)')\n",
    "plt.savefig('total_amount_boxplot.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "# Histogram with KDE\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(x=df['Total_Amount_clean'].dropna().to_numpy(), kde=True, bins=30)\n",
    "plt.title('Histogram of Total_Amount (clean)')\n",
    "plt.xlabel('Total_Amount')\n",
    "plt.savefig('total_amount_hist.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "print('Saved plots: total_amount_boxplot.png, total_amount_hist.png')\n",
    "\n",
    "# Print small samples of outliers for quick inspection\n",
    "print('\\nSample outliers by method:')\n",
    "print('Z-score (first 5):')\n",
    "print(outliers_z.head().to_string())\n",
    "print('\\nTrimmed IQR (first 5):')\n",
    "print(outliers_trimmed.head().to_string())\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated plots inline\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "files = ['total_amount_boxplot.png', 'total_amount_hist.png']\n",
    "for f in files:\n",
    "    if os.path.exists(f):\n",
    "        display(Image(filename=f))\n",
    "    else:\n",
    "        print(f\"File not found in workspace: {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) CALCULATE AND VISUALIZE DESCRIPTIVE STATISTICS\n",
    "# Frequency of Year (use Year_clean when available)\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else 'Year'\n",
    "frequency_table = df[year_col].value_counts()\n",
    "\n",
    "print(\"--- Frequency Count ---\")\n",
    "print(frequency_table)\n",
    "\n",
    "print(\"\\n--- Relative Frequency (Percentage) ---\")\n",
    "# Get the percentage/proportion of each unique value\n",
    "relative_frequency_table = df[year_col].value_counts(normalize=True) * 100\n",
    "print(relative_frequency_table)\n",
    "\n",
    "# Helper function to get clean column if available\n",
    "def pick_clean(df, col):\n",
    "    clean_col = f\"{col}_clean\"\n",
    "    return df[clean_col] if clean_col in df.columns else df[col]\n",
    "\n",
    "# Get clean versions of columns\n",
    "safe_total = pick_clean(df, 'Total_Amount')\n",
    "safe_qty = pick_clean(df, 'Quantity')\n",
    "safe_price = pick_clean(df, 'Unit_Price')\n",
    "safe_scoops = pick_clean(df, 'Number_of_Scoops')\n",
    "\n",
    "def safe_print_mean(series, name):\n",
    "    numeric = pd.to_numeric(series, errors='coerce')\n",
    "    n_total = len(series)\n",
    "    n_numeric = numeric.count()\n",
    "    n_non_numeric = n_total - n_numeric\n",
    "    mean_val = numeric.mean()\n",
    "    print(f\"{name} Mean: {mean_val} (non-numeric coerced to NaN: {n_non_numeric})\")\n",
    "\n",
    "print(\"\\n--- Column Means ---\")\n",
    "safe_print_mean(safe_total, 'Total_Amount')\n",
    "safe_print_mean(safe_qty, 'Quantity')\n",
    "safe_print_mean(safe_price, 'Unit_Price')\n",
    "safe_print_mean(safe_scoops, 'Number_of_Scoops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) CALCULATE AND VISUALIZE DESCRIPTIVE STATISTICS\n",
    "# Frequency of Month AND Year (use cleaned columns when available)\n",
    "month_col = 'Month_clean' if 'Month_clean' in df.columns else 'Month'\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else 'Year'\n",
    "grouped_frequency = df.groupby([month_col, year_col]).size().reset_index(name='Count')\n",
    "\n",
    "# Get the total number of rows in dataframe\n",
    "total_count = len(df)\n",
    "\n",
    "# Calculate the percentage column\n",
    "grouped_frequency['Percentage'] = (grouped_frequency['Count'] / total_count) * 100\n",
    "\n",
    "# Rounding to two decimal places\n",
    "grouped_frequency['Percentage'] = grouped_frequency['Percentage'].round(2)\n",
    "\n",
    "print(\"--- Month and Year Frequency ---\")\n",
    "print(grouped_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) CALCULATE AND VISUALIZE DESCRIPTIVE STATISTICS \n",
    "#Frenquency of Month AND Year\n",
    "grouped_frequency = df.groupby(['Month', 'Year']).size().reset_index(name='Count')\n",
    "\n",
    "#Get the total number of rows in dataframe \n",
    "total_count = len(df) \n",
    "\n",
    "#Calculate the percentage column\n",
    "grouped_frequency['Percentage'] = (grouped_frequency['Count'] / total_count) * 100\n",
    "\n",
    "# Rounding to two decimal places\n",
    "grouped_frequency['Percentage'] = grouped_frequency['Percentage'].round(2)\n",
    "\n",
    "print(grouped_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) CALCULATE AND VISUALIZE DESCRIPTIVE STATISTICS \n",
    "#Frenquency of Customer_ID. Aim to confirm there isn't any outliers among customers. \n",
    "frequency_table = df['Customer_ID'].value_counts()\n",
    "\n",
    "print(\"--- Frequency Count ---\")\n",
    "print(frequency_table)\n",
    "\n",
    "print(\"\\n--- Relative Frequency (Percentage) ---\")\n",
    "# Get the percentage/proportion of each unique value\n",
    "relative_frequency_table = df['Customer_ID'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(relative_frequency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd10111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) CALCULATE AND VISUALIZE DESCRIPTIVE STATISTICS \n",
    "#Min and Max Customer_ID count. What is the min and max times a customer has attended Crafted Cones? \n",
    "import pandas as pd\n",
    "\n",
    "#Attendance per customer \n",
    "attendance_counts = df.groupby('Customer_ID').size().reset_index(name='Attendance_Count')\n",
    "\n",
    "#Min and max values from the new 'Attendance_Count' column\n",
    "min_max_attendance = attendance_counts['Attendance_Count'].agg(['min', 'max'])\n",
    "\n",
    "print(\"--- Min and Max Customer Attendance ---\")\n",
    "print(min_max_attendance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) CALCULATE AND VISUALIZE DESCRIPTIVE STATISTICS \n",
    "#Average and Median customer attendance \n",
    "\n",
    "# Group by customer attendance count \n",
    "attendance_counts = df.groupby('Customer_ID').size().reset_index(name='Attendance_Count')\n",
    "\n",
    "#Find the mean and median of attendance counts\n",
    "average_median_attendance = attendance_counts['Attendance_Count'].agg(['mean', 'median'])\n",
    "\n",
    "print(\"--- Average and Median Customer Attendance ---\")\n",
    "print(average_median_attendance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for summary statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the style\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Helper function to save plots\n",
    "def save_plot(plt, name):\n",
    "    plt.savefig(f'{name}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# 1. Monthly Transaction Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "month_col = 'Month_clean' if 'Month_clean' in df.columns else 'Month'\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else 'Year'\n",
    "pivot_data = df.groupby([month_col, year_col]).size().unstack()\n",
    "sns.heatmap(pivot_data, annot=True, fmt='g', cmap='YlOrRd')\n",
    "plt.title('Monthly Transaction Count by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Month')\n",
    "save_plot(plt, 'monthly_transactions_heatmap')\n",
    "\n",
    "# 2. Customer Visit Frequency Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "attendance_counts = df.groupby('Customer_ID').size()\n",
    "sns.histplot(x=attendance_counts.values, bins=30)\n",
    "plt.title('Distribution of Customer Visit Frequency')\n",
    "plt.xlabel('Number of Visits')\n",
    "plt.ylabel('Number of Customers')\n",
    "save_plot(plt, 'customer_visit_distribution')\n",
    "\n",
    "# 3. Monthly Sales Trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_totals = df.groupby([year_col, month_col])['Total_Amount_clean'].sum().reset_index()\n",
    "for year in monthly_totals[year_col].unique():\n",
    "    year_data = monthly_totals[monthly_totals[year_col] == year]\n",
    "    plt.plot(year_data[month_col], year_data['Total_Amount_clean'], marker='o', label=str(year))\n",
    "plt.title('Monthly Sales Trends by Year')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Sales Amount')\n",
    "plt.legend(title='Year')\n",
    "plt.grid(True)\n",
    "save_plot(plt, 'monthly_sales_trends')\n",
    "\n",
    "# 4. Average Transaction Value by Month\n",
    "plt.figure(figsize=(12, 6))\n",
    "avg_transaction = df.groupby([year_col, month_col])['Total_Amount_clean'].mean().reset_index()\n",
    "for year in avg_transaction[year_col].unique():\n",
    "    year_data = avg_transaction[avg_transaction[year_col] == year]\n",
    "    plt.plot(year_data[month_col], year_data['Total_Amount_clean'], marker='o', label=str(year))\n",
    "plt.title('Average Transaction Value by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Transaction Amount')\n",
    "plt.legend(title='Year')\n",
    "plt.grid(True)\n",
    "save_plot(plt, 'avg_transaction_by_month')\n",
    "\n",
    "# 5. Transaction Amount Distribution by Month\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x=month_col, y='Total_Amount_clean')\n",
    "plt.title('Transaction Amount Distribution by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Transaction Amount')\n",
    "save_plot(plt, 'transaction_amount_distribution')\n",
    "\n",
    "# 6. Number of Scoops Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "scoops_col = 'Number_of_Scoops_clean' if 'Number_of_Scoops_clean' in df.columns else 'Number_of_Scoops'\n",
    "sns.histplot(data=df, x=scoops_col, discrete=True)\n",
    "plt.title('Distribution of Number of Scoops per Transaction')\n",
    "plt.xlabel('Number of Scoops')\n",
    "plt.ylabel('Count')\n",
    "save_plot(plt, 'scoops_distribution')\n",
    "\n",
    "# 7. Correlation: Scoops vs Total Amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x=scoops_col, y='Total_Amount_clean', alpha=0.5)\n",
    "plt.title('Correlation: Number of Scoops vs Total Amount')\n",
    "plt.xlabel('Number of Scoops')\n",
    "plt.ylabel('Total Amount')\n",
    "save_plot(plt, 'scoops_vs_total_correlation')\n",
    "\n",
    "# 8. Top 10 Customers\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_customers = df.groupby('Customer_ID').size().sort_values(ascending=False).head(10)\n",
    "sns.barplot(x=top_customers.values, y=top_customers.index)\n",
    "plt.title('Top 10 Customers by Number of Visits')\n",
    "plt.xlabel('Number of Visits')\n",
    "plt.ylabel('Customer ID')\n",
    "save_plot(plt, 'top_10_customers')\n",
    "\n",
    "print(\"\\nVisualizations have been generated and saved as separate PNG files:\")\n",
    "print(\"1. monthly_transactions_heatmap.png\")\n",
    "print(\"2. customer_visit_distribution.png\")\n",
    "print(\"3. monthly_sales_trends.png\")\n",
    "print(\"4. avg_transaction_by_month.png\")\n",
    "print(\"5. transaction_amount_distribution.png\")\n",
    "print(\"6. scoops_distribution.png\")\n",
    "print(\"7. scoops_vs_total_correlation.png\")\n",
    "print(\"8. top_10_customers.png\")\n",
    "\n",
    "# Calculate and print key correlations\n",
    "print(\"\\nKey Correlations:\")\n",
    "correlations = df[[scoops_col, 'Total_Amount_clean', 'Quantity_clean']].corr()\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a8106",
   "metadata": {},
   "source": [
    "## Sales Growth Forecasting (Train/Test Split)\n",
    "\n",
    "This section introduces a minimal, interpretable sales growth forecasting workflow using the cleaned transaction data.\n",
    "\n",
    "Approach:\n",
    "- Aggregate total sales by Year/Month using cleaned columns (`Total_Amount_clean`, `Year_clean`, `Month_clean`).\n",
    "- Construct a continuous monthly time index (YYYY-MM) and ensure chronological ordering.\n",
    "- Perform a simple train/test split: last N months reserved for test (default N = 3 if >= 9 total months else N = 2, else fallback to leave 1 for test if possible).\n",
    "- Baseline Forecast Methods:\n",
    "  1. Naive (last observed month value).\n",
    "  2. Seasonal Naive (value from same month previous year, if available; fallback to naive).\n",
    "  3. Simple Moving Average (mean of last K months, K=3; requires enough history; fallback to naive).\n",
    "- Metrics Computed on Test:\n",
    "  - MAE (Mean Absolute Error)\n",
    "  - RMSE (Root Mean Squared Error)\n",
    "  - MAPE (Mean Absolute Percentage Error) with protection against division by zero\n",
    "  - sMAPE (Symmetric MAPE)\n",
    "  - Directional Accuracy (whether forecasted growth direction matches actual month-over-month change)\n",
    "- Growth Calculation:\n",
    "  - Month-over-month growth rate = (Current - Previous) / Previous for actuals & forecasts.\n",
    "\n",
    "Assumptions:\n",
    "- Data frequency is monthly and sufficiently dense; no gaps or missing months. If gaps exist, they are forward-filled with 0 sales for continuity.\n",
    "- Cleaned columns exist; if not, raw columns are used with warnings.\n",
    "- Sales amounts are non-negative.\n",
    "\n",
    "Limitations:\n",
    "- Does not model trend explicitly (no regression, ARIMA, or ETS components).\n",
    "- Seasonal naive requires at least 12 months history; otherwise it reduces to naive.\n",
    "- Moving average can lag turning points.\n",
    "- MAPE can be distorted by near-zero actuals; sMAPE reduces this impact.\n",
    "\n",
    "Outputs:\n",
    "- Printed metric table.\n",
    "- Plot of actual vs each forecast method over train/test period, saved to `forecast_comparison.png`.\n",
    "- CSV `forecast_results.csv` containing per-test-month actuals and forecasts.\n",
    "\n",
    "Next Steps (not implemented here):\n",
    "- Evaluate advanced models (e.g., SARIMA, Prophet, Gradient Boosted Trees on lag features).\n",
    "- Add holiday/promotion features.\n",
    "- Conduct residual diagnostics and rolling-origin evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1201a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Growth Forecasting Code Cell\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Identify columns (fallbacks if clean not present)\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else ('Year' if 'Year' in df.columns else None)\n",
    "month_col = 'Month_clean' if 'Month_clean' in df.columns else ('Month' if 'Month' in df.columns else None)\n",
    "total_col = 'Total_Amount_clean' if 'Total_Amount_clean' in df.columns else ('Total_Amount' if 'Total_Amount' in df.columns else None)\n",
    "\n",
    "if not all([year_col, month_col, total_col]):\n",
    "    raise ValueError('Required columns for forecasting (Year, Month, Total_Amount) not found.')\n",
    "\n",
    "# Aggregate monthly sales (avoid chained column indexing to satisfy type checker)\n",
    "monthly = df.groupby([year_col, month_col], as_index=False).agg({total_col: 'sum'})\n",
    "monthly.rename(columns={year_col: 'Year', month_col: 'Month', total_col: 'Sales'}, inplace=True)\n",
    "\n",
    "# Coerce types\n",
    "monthly['Year'] = pd.to_numeric(monthly['Year'], errors='coerce')\n",
    "monthly['Month'] = pd.to_numeric(monthly['Month'], errors='coerce')\n",
    "monthly = monthly.dropna(subset=['Year','Month'])\n",
    "\n",
    "# Build a date key (assumes Month 1..12)\n",
    "monthly['Month'] = monthly['Month'].astype(int)\n",
    "monthly = monthly.sort_values(['Year','Month'])\n",
    "monthly['Date'] = pd.to_datetime(monthly[['Year','Month']].assign(DAY=1))\n",
    "\n",
    "# Fill missing months if any (continuous range)\n",
    "full_range = pd.date_range(monthly['Date'].min(), monthly['Date'].max(), freq='MS')\n",
    "monthly_full = pd.DataFrame({'Date': full_range})\n",
    "monthly_full = monthly_full.merge(monthly[['Date','Sales']], on='Date', how='left')\n",
    "monthly_full['Sales'] = monthly_full['Sales'].fillna(0)  # assumption: missing months have zero sales\n",
    "\n",
    "n_months = len(monthly_full)\n",
    "if n_months < 4:\n",
    "    raise ValueError(f'Not enough monthly data ({n_months} months) to perform a train/test split.')\n",
    "\n",
    "# Determine test size\n",
    "if n_months >= 9:\n",
    "    test_size = 3\n",
    "elif n_months >= 6:\n",
    "    test_size = 2\n",
    "else:\n",
    "    test_size = 1\n",
    "\n",
    "train = monthly_full.iloc[:-test_size].copy()\n",
    "test = monthly_full.iloc[-test_size:].copy()\n",
    "\n",
    "# Forecast methods\n",
    "# 1) Naive: last observed sales value repeated\n",
    "def naive_forecast(train_series, horizon):\n",
    "    last_val = train_series.iloc[-1]\n",
    "    return np.repeat(last_val, horizon)\n",
    "\n",
    "# 2) Seasonal naive: value from same month previous year\n",
    "# Requires at least 12 months history; fallback to naive if insufficient\n",
    "months_in_year = 12\n",
    "if len(train) >= months_in_year:\n",
    "    def seasonal_naive_forecast(train_df, horizon):\n",
    "        fc = []\n",
    "        for i in range(horizon):\n",
    "            target_date = test['Date'].iloc[i]\n",
    "            prev_year_date = target_date - pd.DateOffset(years=1)\n",
    "            match = train_df.loc[train_df['Date'] == prev_year_date, 'Sales']\n",
    "            if not match.empty:\n",
    "                fc.append(match.values[0])\n",
    "            else:\n",
    "                fc.append(train_df['Sales'].iloc[-1])  # fallback to last\n",
    "        return np.array(fc)\n",
    "else:\n",
    "    seasonal_naive_forecast = lambda train_df, horizon: naive_forecast(train_df['Sales'], horizon)\n",
    "\n",
    "# 3) Moving average (window=3) fallback to naive if insufficient history\n",
    "def moving_average_forecast(train_series, horizon, window=3):\n",
    "    if len(train_series) < window:\n",
    "        return naive_forecast(train_series, horizon)\n",
    "    avg_val = train_series.iloc[-window:].mean()\n",
    "    return np.repeat(avg_val, horizon)\n",
    "\n",
    "# Generate forecasts\n",
    "h = test_size\n",
    "naive_fc = naive_forecast(train['Sales'], h)\n",
    "seasonal_fc = seasonal_naive_forecast(train, h)\n",
    "ma_fc = moving_average_forecast(train['Sales'], h, window=3)\n",
    "\n",
    "# Combine into DataFrame\n",
    "results = test[['Date']].copy()\n",
    "results['Actual'] = test['Sales'].values\n",
    "results['Naive_Forecast'] = naive_fc\n",
    "results['Seasonal_Naive_Forecast'] = seasonal_fc\n",
    "results['MA3_Forecast'] = ma_fc\n",
    "\n",
    "# Error metrics helpers\n",
    "def safe_div(a,b):\n",
    "    return np.where(b==0, np.nan, a/b)\n",
    "\n",
    "def mae(a,f):\n",
    "    return np.mean(np.abs(a-f))\n",
    "\n",
    "def rmse(a,f):\n",
    "    return np.sqrt(np.mean((a-f)**2))\n",
    "\n",
    "def mape(a,f):\n",
    "    return np.nanmean(np.abs(safe_div(a-f,a))) * 100\n",
    "\n",
    "def smape(a,f):\n",
    "    return np.nanmean(np.abs(a-f) / ((np.abs(a)+np.abs(f))/2)) * 100\n",
    "\n",
    "# Directional accuracy (growth direction)\n",
    "# Growth defined vs previous actual for actual, previous forecast value for forecast\n",
    "results['Actual_prev'] = test['Sales'].shift(1)\n",
    "results['Naive_prev'] = naive_fc[:-1].tolist() + [naive_fc[-1]]  # simple shift approximation\n",
    "# Compute growth direction actual & forecast (only where previous actual not NaN)\n",
    "results['Actual_Growth'] = safe_div(results['Actual'] - results['Actual_prev'], results['Actual_prev'])\n",
    "results['Naive_Growth'] = safe_div(results['Naive_Forecast'] - results['Actual_prev'], results['Actual_prev'])\n",
    "# Directional accuracy where both growths available\n",
    "direction_mask = results['Actual_Growth'].notna() & results['Naive_Growth'].notna()\n",
    "if direction_mask.any():\n",
    "    directional_accuracy = np.mean(np.sign(results.loc[direction_mask,'Actual_Growth']) == np.sign(results.loc[direction_mask,'Naive_Growth']))\n",
    "else:\n",
    "    directional_accuracy = np.nan\n",
    "\n",
    "metrics_rows = []\n",
    "for label, fc in [('Naive', 'Naive_Forecast'), ('Seasonal_Naive','Seasonal_Naive_Forecast'), ('MA3','MA3_Forecast')]:\n",
    "    a = results['Actual'].values\n",
    "    f = results[fc].values\n",
    "    metrics_rows.append({\n",
    "        'Model': label,\n",
    "        'MAE': mae(a,f),\n",
    "        'RMSE': rmse(a,f),\n",
    "        'MAPE%': mape(a,f),\n",
    "        'sMAPE%': smape(a,f)\n",
    "    })\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "\n",
    "print('--- Forecast Metrics (Test Set) ---')\n",
    "print(metrics_df.round(3))\n",
    "print('\\nDirectional Accuracy (Naive growth direction):', round(directional_accuracy,3) if not np.isnan(directional_accuracy) else 'N/A')\n",
    "\n",
    "# Plot actual vs forecasts\n",
    "sns.set_theme(style='whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "all_series = pd.concat([train, test])\n",
    "ax.plot(train['Date'], train['Sales'], label='Train Actual', color='gray')\n",
    "ax.plot(test['Date'], test['Sales'], label='Test Actual', color='black', linewidth=2)\n",
    "ax.plot(results['Date'], results['Naive_Forecast'], label='Naive', linestyle='--')\n",
    "ax.plot(results['Date'], results['Seasonal_Naive_Forecast'], label='Seasonal Naive', linestyle='--')\n",
    "ax.plot(results['Date'], results['MA3_Forecast'], label='MA(3)', linestyle='--')\n",
    "ax.set_title('Monthly Sales: Actual vs Baseline Forecasts')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sales')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "fig_path = 'forecast_comparison.png'\n",
    "fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "print(f'Plot saved: {fig_path}')\n",
    "\n",
    "# Export detailed results\n",
    "export_df = results[['Date','Actual','Naive_Forecast','Seasonal_Naive_Forecast','MA3_Forecast']]\n",
    "export_path = 'forecast_results.csv'\n",
    "export_df.to_csv(export_path, index=False)\n",
    "print(f'Results CSV saved: {export_path}')\n",
    "\n",
    "# Brief textual interpretation\n",
    "best_model = metrics_df.sort_values('MAE').iloc[0]['Model']\n",
    "print('\\nInterpretation:')\n",
    "print(f'- Best baseline by MAE: {best_model}')\n",
    "print('- Seasonal naive only adds value if >= 12 months history and pattern repeats. Check sMAPE for robustness when near-zero months exist.')\n",
    "print('- Moving average smooths volatility but can lag sudden changes.')\n",
    "print('- Consider adding trend/seasonality modeling for improved accuracy.')\n",
    "\n",
    "# Guardrail info\n",
    "print('\\nGuardrails & Notes:')\n",
    "print('- Missing months were filled with zero sales; this may understate seasonality amplitude.')\n",
    "print('- MAPE can be inflated when actual values are near zero; sMAPE reduces this sensitivity.')\n",
    "print('- Directional accuracy uses naive forecast growth direction as baseline comparator.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45213a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling-Origin Backtest (Time-Series Cross-Validation) for Baselines\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Ensure base DataFrame is loaded if kernel restarted\n",
    "if 'df' not in globals():\n",
    "    df = pd.read_csv('2025.09.29_2023_Sales_Transactions_Only.csv')\n",
    "    # Attempt minimal cleaning for key columns if cleaned versions missing\n",
    "    if 'Total_Amount_clean' not in df.columns and 'Total_Amount' in df.columns:\n",
    "        temp = df['Total_Amount'].astype(str).str.strip()\n",
    "        temp = temp.replace('nan','',regex=False)\n",
    "        neg_mask = temp.str.match(r'^\\(.*\\)$')\n",
    "        temp = temp.str.replace(r'[\\(\\)]','',regex=True)\n",
    "        temp = temp.str.replace(r'[\\$,\\s]','',regex=True)\n",
    "        if neg_mask.any():\n",
    "            temp.loc[neg_mask] = '-' + temp.loc[neg_mask]\n",
    "        df['Total_Amount_clean'] = pd.to_numeric(temp, errors='coerce')\n",
    "    for c in ['Year','Month']:\n",
    "        if f'{c}_clean' not in df.columns and c in df.columns:\n",
    "            df[f'{c}_clean'] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Column resolution\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else ('Year' if 'Year' in df.columns else None)\n",
    "month_col = 'Month_clean' if 'Month_clean' in df.columns else ('Month' if 'Month' in df.columns else None)\n",
    "total_col = 'Total_Amount_clean' if 'Total_Amount_clean' in df.columns else ('Total_Amount' if 'Total_Amount' in df.columns else None)\n",
    "if not all([year_col, month_col, total_col]):\n",
    "    raise ValueError('Required columns for backtest (Year, Month, Total_Amount) not found.')\n",
    "\n",
    "# Aggregate monthly with explicit dict to satisfy type checkers\n",
    "monthly = df.groupby([year_col, month_col], as_index=False).agg({total_col: 'sum'})\n",
    "monthly.rename(columns={year_col: 'Year', month_col: 'Month', total_col: 'Sales'}, inplace=True)\n",
    "monthly['Year'] = pd.to_numeric(monthly['Year'], errors='coerce')\n",
    "monthly['Month'] = pd.to_numeric(monthly['Month'], errors='coerce')\n",
    "monthly = monthly.dropna(subset=['Year','Month'])\n",
    "monthly['Month'] = monthly['Month'].astype(int)\n",
    "monthly = monthly.sort_values(['Year','Month'])\n",
    "monthly['Date'] = pd.to_datetime(monthly[['Year','Month']].assign(DAY=1))\n",
    "full_range = pd.date_range(monthly['Date'].min(), monthly['Date'].max(), freq='MS')\n",
    "series = (\n",
    "    pd.DataFrame({'Date': full_range})\n",
    "    .merge(monthly[['Date','Sales']], on='Date', how='left')\n",
    "    .fillna({'Sales':0})\n",
    ")\n",
    "\n",
    "A = series['Sales'].values.astype(float)\n",
    "D = series['Date']\n",
    "N = len(series)\n",
    "if N < 8:\n",
    "    raise ValueError(f'Not enough months ({N}) for a meaningful rolling-origin backtest.')\n",
    "\n",
    "min_train = 12 if N >= 18 else 6\n",
    "\n",
    "# Metric helpers\n",
    "def safe_div(a,b):\n",
    "    b = np.asarray(b)\n",
    "    return np.where(b==0, np.nan, a/b)\n",
    "\n",
    "def mae(a,f):\n",
    "    return np.nanmean(np.abs(a-f))\n",
    "\n",
    "def rmse(a,f):\n",
    "    return np.sqrt(np.nanmean((a-f)**2))\n",
    "\n",
    "def mape(a,f):\n",
    "    return np.nanmean(np.abs(safe_div(a-f,a))) * 100\n",
    "\n",
    "def smape(a,f):\n",
    "    return np.nanmean(np.abs(a-f) / ((np.abs(a)+np.abs(f))/2)) * 100\n",
    "\n",
    "rows = []\n",
    "for t in range(min_train-1, N-1):\n",
    "    train_slice = slice(0, t+1)\n",
    "    y_train = A[train_slice]\n",
    "    y_next = A[t+1]\n",
    "    date_next = D.iloc[t+1]\n",
    "\n",
    "    # Naive\n",
    "    naive_pred = y_train[-1]\n",
    "\n",
    "    # Seasonal Naive (12-month)\n",
    "    if t+1-12 >= 0:\n",
    "        seas_pred = A[t+1-12]\n",
    "    else:\n",
    "        seas_pred = naive_pred\n",
    "\n",
    "    # MA(3)\n",
    "    if len(y_train) >= 3:\n",
    "        ma3_pred = np.nanmean(y_train[-3:])\n",
    "    else:\n",
    "        ma3_pred = naive_pred\n",
    "\n",
    "    rows.append({\n",
    "        'Date': date_next, 'Actual': y_next,\n",
    "        'Naive': naive_pred,\n",
    "        'Seasonal_Naive': seas_pred,\n",
    "        'MA3': ma3_pred\n",
    "    })\n",
    "\n",
    "bt = pd.DataFrame(rows)\n",
    "\n",
    "metrics = []\n",
    "for name in ['Naive','Seasonal_Naive','MA3']:\n",
    "    a = bt['Actual'].values\n",
    "    f = bt[name].values\n",
    "    metrics.append({'Model': name,\n",
    "                    'MAE': mae(a,f),\n",
    "                    'RMSE': rmse(a,f),\n",
    "                    'MAPE%': mape(a,f),\n",
    "                    'sMAPE%': smape(a,f)})\n",
    "metrics_df = pd.DataFrame(metrics).round(3)\n",
    "print(\"--- Rolling-Origin Backtest Metrics (1-step ahead, multiple folds) ---\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Save metrics\n",
    "bt_metrics_path = 'rolling_backtest_metrics.csv'\n",
    "metrics_df.to_csv(bt_metrics_path, index=False)\n",
    "print(f'Metrics CSV saved: {bt_metrics_path}')\n",
    "\n",
    "# Plot last 24 months of backtest results\n",
    "plot_tail = min(24, len(bt))\n",
    "sns.set_theme(style='whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(bt['Date'].tail(plot_tail), bt['Actual'].tail(plot_tail), label='Actual', color='black', linewidth=2)\n",
    "ax.plot(bt['Date'].tail(plot_tail), bt['Naive'].tail(plot_tail), label='Naive', linestyle='--')\n",
    "ax.plot(bt['Date'].tail(plot_tail), bt['Seasonal_Naive'].tail(plot_tail), label='Seasonal Naive', linestyle='--')\n",
    "ax.plot(bt['Date'].tail(plot_tail), bt['MA3'].tail(plot_tail), label='MA(3)', linestyle='--')\n",
    "ax.set_title('Rolling-Origin Backtest: Last 24 Months (1-step ahead)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sales')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plot_path = 'rolling_backtest_plot.png'\n",
    "fig.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "print(f'Plot saved: {plot_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c218078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA and Prophet Modeling Comparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "\n",
    "# Reload monthly series (reuse logic)\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else ('Year' if 'Year' in df.columns else None)\n",
    "month_col = 'Month_clean' if 'Month_clean' in df.columns else ('Month' if 'Month' in df.columns else None)\n",
    "total_col = 'Total_Amount_clean' if 'Total_Amount_clean' in df.columns else ('Total_Amount' if 'Total_Amount' in df.columns else None)\n",
    "if not all([year_col, month_col, total_col]):\n",
    "    raise ValueError('Required columns for advanced models not found.')\n",
    "\n",
    "monthly = df.groupby([year_col, month_col])[total_col].sum().reset_index()\n",
    "monthly.rename(columns={year_col: 'Year', month_col: 'Month', total_col: 'Sales'}, inplace=True)\n",
    "monthly['Year'] = pd.to_numeric(monthly['Year'], errors='coerce')\n",
    "monthly['Month'] = pd.to_numeric(monthly['Month'], errors='coerce')\n",
    "monthly = monthly.dropna(subset=['Year','Month'])\n",
    "monthly['Month'] = monthly['Month'].astype(int)\n",
    "monthly = monthly.sort_values(['Year','Month'])\n",
    "monthly['Date'] = pd.to_datetime(monthly[['Year','Month']].assign(DAY=1))\n",
    "full_range = pd.date_range(monthly['Date'].min(), monthly['Date'].max(), freq='MS')\n",
    "series = (\n",
    "    pd.DataFrame({'Date': full_range})\n",
    "    .merge(monthly[['Date','Sales']], on='Date', how='left')\n",
    "    .fillna({'Sales':0})\n",
    ")\n",
    "\n",
    "# Train/Test (reuse same split logic)\n",
    "N = len(series)\n",
    "if N < 8:\n",
    "    raise ValueError('Insufficient data for advanced comparison.')\n",
    "if N >= 9:\n",
    "    test_size = 3\n",
    "elif N >= 6:\n",
    "    test_size = 2\n",
    "else:\n",
    "    test_size = 1\n",
    "train = series.iloc[:-test_size].copy()\n",
    "test = series.iloc[-test_size:].copy()\n",
    "\n",
    "# =============== SARIMA ===============\n",
    "# Simple SARIMA config heuristic: (1,1,1) with seasonal (1,1,1,12) if length >= 24 else non-seasonal fallback\n",
    "use_seasonal = N >= 24\n",
    "order = (1,1,1)\n",
    "seasonal_order = (1,1,1,12) if use_seasonal else (0,0,0,0)\n",
    "try:\n",
    "    sarima_model = SARIMAX(train['Sales'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    sarima_res = sarima_model.fit(disp=False)\n",
    "    sarima_fc = sarima_res.forecast(steps=test_size).values\n",
    "except Exception as e:\n",
    "    print('SARIMA failed, falling back to naive. Error:', e)\n",
    "    sarima_fc = np.repeat(train['Sales'].iloc[-1], test_size)\n",
    "\n",
    "# =============== Prophet ===============\n",
    "# Prepare data for Prophet\n",
    "prophet_df = train[['Date','Sales']].rename(columns={'Date':'ds','Sales':'y'})\n",
    "# Add simple yearly seasonality; Prophet auto-detects\n",
    "try:\n",
    "    prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "    prophet_model.fit(prophet_df)\n",
    "    future = prophet_model.make_future_dataframe(periods=test_size, freq='MS')\n",
    "    forecast = prophet_model.predict(future)\n",
    "    prophet_fc = forecast.tail(test_size)['yhat'].values\n",
    "except Exception as e:\n",
    "    print('Prophet failed, falling back to naive. Error:', e)\n",
    "    prophet_fc = np.repeat(train['Sales'].iloc[-1], test_size)\n",
    "\n",
    "# Baseline naive for comparison\n",
    "naive_fc = np.repeat(train['Sales'].iloc[-1], test_size)\n",
    "\n",
    "# Metrics helpers\n",
    "def safe_div(a,b):\n",
    "    return np.where(b==0, np.nan, a/b)\n",
    "\n",
    "def mae(a,f):\n",
    "    return np.mean(np.abs(a-f))\n",
    "\n",
    "def rmse(a,f):\n",
    "    return np.sqrt(np.mean((a-f)**2))\n",
    "\n",
    "def mape(a,f):\n",
    "    return np.nanmean(np.abs(safe_div(a-f,a))) * 100\n",
    "\n",
    "def smape(a,f):\n",
    "    return np.nanmean(np.abs(a-f) / ((np.abs(a)+np.abs(f))/2)) * 100\n",
    "\n",
    "actual = test['Sales'].values\n",
    "comparison = []\n",
    "for name, fc in [('Naive', naive_fc), ('SARIMA', sarima_fc), ('Prophet', prophet_fc)]:\n",
    "    comparison.append({'Model': name,\n",
    "                       'MAE': mae(actual, fc),\n",
    "                       'RMSE': rmse(actual, fc),\n",
    "                       'MAPE%': mape(actual, fc),\n",
    "                       'sMAPE%': smape(actual, fc)})\n",
    "metrics_adv = pd.DataFrame(comparison).round(3)\n",
    "print('\\n--- Advanced Models vs Naive (Test Set) ---')\n",
    "print(metrics_adv)\n",
    "\n",
    "# Save metrics\n",
    "adv_metrics_path = 'advanced_model_metrics.csv'\n",
    "metrics_adv.to_csv(adv_metrics_path, index=False)\n",
    "print(f'Metrics CSV saved: {adv_metrics_path}')\n",
    "\n",
    "# Plot comparison\n",
    "sns.set_theme(style='whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(train['Date'], train['Sales'], label='Train Actual', color='gray')\n",
    "ax.plot(test['Date'], test['Sales'], label='Test Actual', color='black', linewidth=2)\n",
    "ax.plot(test['Date'], naive_fc, label='Naive', linestyle='--')\n",
    "ax.plot(test['Date'], sarima_fc, label='SARIMA', linestyle='--')\n",
    "ax.plot(test['Date'], prophet_fc, label='Prophet', linestyle='--')\n",
    "ax.set_title('Advanced Models Forecast Comparison')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sales')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "adv_plot_path = 'advanced_models_comparison.png'\n",
    "fig.savefig(adv_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "print(f'Plot saved: {adv_plot_path}')\n",
    "\n",
    "# Display quick ranking\n",
    "best_adv = metrics_adv.sort_values('MAE').iloc[0]['Model']\n",
    "print(f'Best model by MAE: {best_adv}')\n",
    "print('Note: Prophet & SARIMA performance may be constrained by short history length.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d481a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling-Origin Backtest for Advanced Models (SARIMA & Prophet)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure df is available (kernel-safe)\n",
    "if 'df' not in globals():\n",
    "    df = pd.read_csv('2025.09.29_2023_Sales_Transactions_Only.csv')\n",
    "    # Minimal cleaning for critical columns\n",
    "    if 'Total_Amount_clean' not in df.columns and 'Total_Amount' in df.columns:\n",
    "        temp = df['Total_Amount'].astype(str).str.strip()\n",
    "        temp = temp.replace('nan','',regex=False)\n",
    "        neg_mask = temp.str.match(r'^\\(.*\\)$')\n",
    "        temp = temp.str.replace(r'[\\(\\)]','',regex=True)\n",
    "        temp = temp.str.replace(r'[\\$,\\s]','',regex=True)\n",
    "        if neg_mask.any():\n",
    "            temp.loc[neg_mask] = '-' + temp.loc[neg_mask]\n",
    "        df['Total_Amount_clean'] = pd.to_numeric(temp, errors='coerce')\n",
    "    for c in ['Year','Month']:\n",
    "        if f'{c}_clean' not in df.columns and c in df.columns:\n",
    "            df[f'{c}_clean'] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Build monthly series\n",
    "year_col = 'Year_clean' if 'Year_clean' in df.columns else ('Year' if 'Year' in df.columns else None)\n",
    "month_col = 'Month_clean' if 'Month_clean' in df.columns else ('Month' if 'Month' in df.columns else None)\n",
    "total_col = 'Total_Amount_clean' if 'Total_Amount_clean' in df.columns else ('Total_Amount' if 'Total_Amount' in df.columns else None)\n",
    "if not all([year_col, month_col, total_col]):\n",
    "    raise ValueError('Required columns for rolling-origin advanced models not found.')\n",
    "\n",
    "monthly = df.groupby([year_col, month_col])[total_col].sum().reset_index()\n",
    "monthly.rename(columns={year_col: 'Year', month_col: 'Month', total_col: 'Sales'}, inplace=True)\n",
    "monthly['Year'] = pd.to_numeric(monthly['Year'], errors='coerce')\n",
    "monthly['Month'] = pd.to_numeric(monthly['Month'], errors='coerce')\n",
    "monthly = monthly.dropna(subset=['Year','Month'])\n",
    "monthly['Month'] = monthly['Month'].astype(int)\n",
    "monthly = monthly.sort_values(['Year','Month'])\n",
    "monthly['Date'] = pd.to_datetime(monthly[['Year','Month']].assign(DAY=1))\n",
    "full_range = pd.date_range(monthly['Date'].min(), monthly['Date'].max(), freq='MS')\n",
    "series = (\n",
    "    pd.DataFrame({'Date': full_range})\n",
    "    .merge(monthly[['Date','Sales']], on='Date', how='left')\n",
    "    .fillna({'Sales':0})\n",
    ")\n",
    "\n",
    "N = len(series)\n",
    "if N < 8:\n",
    "    raise ValueError(f'Only {N} months available. Need at least 8 for rolling-origin on advanced models.')\n",
    "\n",
    "# Rolling window config\n",
    "min_train = 12 if N >= 24 else 6\n",
    "max_folds = min(12, N - min_train)  # keep runtime reasonable\n",
    "start_t = (N - 1 - max_folds)\n",
    "start_t = max(start_t, min_train - 1)\n",
    "\n",
    "use_seasonal = N >= 24\n",
    "order = (1,1,1)\n",
    "seasonal_order = (1,1,1,12) if use_seasonal else (0,0,0,0)\n",
    "\n",
    "rows = []\n",
    "for t in range(start_t, N-1):\n",
    "    train_fold = series.iloc[:t+1].copy()\n",
    "    next_date = series['Date'].iloc[t+1]\n",
    "    y_train = train_fold['Sales']\n",
    "\n",
    "    # SARIMA\n",
    "    try:\n",
    "        sarima_model = SARIMAX(y_train, order=order, seasonal_order=seasonal_order,\n",
    "                               enforce_stationarity=False, enforce_invertibility=False)\n",
    "        sarima_res = sarima_model.fit(disp=False)\n",
    "        sarima_pred = sarima_res.forecast(steps=1).iloc[0]\n",
    "    except Exception as e:\n",
    "        print(f'SARIMA fold {t} failed: {e}. Using naive fallback for this fold.')\n",
    "        sarima_pred = y_train.iloc[-1]\n",
    "\n",
    "    # Prophet\n",
    "    try:\n",
    "        prophet_df = train_fold[['Date','Sales']].rename(columns={'Date':'ds','Sales':'y'})\n",
    "        m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "        m.fit(prophet_df)\n",
    "        future = m.make_future_dataframe(periods=1, freq='MS')\n",
    "        fc = m.predict(future)\n",
    "        prophet_pred = fc.tail(1)['yhat'].iloc[0]\n",
    "    except Exception as e:\n",
    "        print(f'Prophet fold {t} failed: {e}. Using naive fallback for this fold.')\n",
    "        prophet_pred = y_train.iloc[-1]\n",
    "\n",
    "    rows.append({'Date': next_date,\n",
    "                 'Actual': series['Sales'].iloc[t+1],\n",
    "                 'SARIMA': float(sarima_pred),\n",
    "                 'Prophet': float(prophet_pred)})\n",
    "\n",
    "bt_adv = pd.DataFrame(rows)\n",
    "\n",
    "# Metrics\n",
    "def safe_div(a,b):\n",
    "    return np.where(b==0, np.nan, a/b)\n",
    "\n",
    "def mae(a,f):\n",
    "    return np.nanmean(np.abs(a-f))\n",
    "\n",
    "def rmse(a,f):\n",
    "    return np.sqrt(np.nanmean((a-f)**2))\n",
    "\n",
    "def mape(a,f):\n",
    "    return np.nanmean(np.abs(safe_div(a-f,a))) * 100\n",
    "\n",
    "def smape(a,f):\n",
    "    return np.nanmean(np.abs(a-f) / ((np.abs(a)+np.abs(f))/2)) * 100\n",
    "\n",
    "metrics = []\n",
    "actual = bt_adv['Actual'].values\n",
    "for name in ['SARIMA','Prophet']:\n",
    "    f = bt_adv[name].values\n",
    "    metrics.append({'Model': name,\n",
    "                    'Folds': len(bt_adv),\n",
    "                    'MAE': mae(actual, f),\n",
    "                    'RMSE': rmse(actual, f),\n",
    "                    'MAPE%': mape(actual, f),\n",
    "                    'sMAPE%': smape(actual, f)})\n",
    "metrics_adv_cv = pd.DataFrame(metrics).round(3)\n",
    "print('\\n--- Rolling-Origin Backtest (Advanced Models, 1-step ahead) ---')\n",
    "print(metrics_adv_cv)\n",
    "\n",
    "# Save metrics and plot\n",
    "adv_cv_metrics_path = 'rolling_backtest_advanced_metrics.csv'\n",
    "metrics_adv_cv.to_csv(adv_cv_metrics_path, index=False)\n",
    "print(f'Metrics CSV saved: {adv_cv_metrics_path}')\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plot_tail = min(24, len(bt_adv))\n",
    "ax.plot(bt_adv['Date'].tail(plot_tail), bt_adv['Actual'].tail(plot_tail), label='Actual', color='black', linewidth=2)\n",
    "ax.plot(bt_adv['Date'].tail(plot_tail), bt_adv['SARIMA'].tail(plot_tail), label='SARIMA', linestyle='--')\n",
    "ax.plot(bt_adv['Date'].tail(plot_tail), bt_adv['Prophet'].tail(plot_tail), label='Prophet', linestyle='--')\n",
    "ax.set_title('Rolling-Origin Backtest (Advanced Models): Last Folds')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sales')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "adv_cv_plot_path = 'rolling_backtest_advanced_plot.png'\n",
    "fig.savefig(adv_cv_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "print(f'Plot saved: {adv_cv_plot_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
